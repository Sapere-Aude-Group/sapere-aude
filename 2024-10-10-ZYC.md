---
title: 情感表达的视听整合
author: 朱英策
date: 2024-10-10
showDate: true
showTOC: true
---
# 论文信息
Collignon O, Girard S, Gosselin F, Roy S, Saint-Amour D, Lassonde M, Lepore F. Audio-visual integration of emotion expression. Brain Res. 2008 Nov 25;1242:126-35. doi: 10.1016/j.brainres.2008.04.023. Epub 2008 Apr 20. PMID: 18495094.

# [论文原文](D:\研究生\Sapere Aude\文章\visual-audio integration)
# 关键词
多感官的；情感；厌恶；恐惧
# 摘要
本研究展示了关于使用了新验证的动态视觉与非语言的声音片段表达情绪的多感官知觉。实验1中，参与者被要求按照呈现的听觉的、视觉的，或者使用一致或不一致的视听刺激来将恐惧和厌恶的表情分类。结果表明，在视觉刺激与听觉刺激不一致时，视觉优先，视觉占主导。当视觉刺激的可靠性降低时，被试优先通过听觉对刺激进行分类。在实验2中，被试被要求只注意一种感官模态，来测试多感官情感交互的强制性。结果表明，即使被试被要求忽略并发的其他感觉信息，但是不相关的信息会显著影响对目标的处理。上述实验结果表明，情绪表达的感知是一个强大的多感官情境，且遵循之前在其他领域观察到的规则。



# 1. 简介
情感感知，就像言语感知，是一种特殊的情况，从面部和对话者的声音中所表达的信息相结合，可以优化事件识别。最近，一些研究探索了情感表达的多感官本质。该研究指出，面部表情和情感韵律之间信息的一致性促进了对情绪刺激的行为反应，且通过一种感觉获得的信息可以改变另一感觉的信息处理。也有少数的例外，对情绪表达的双峰感知的研究则使用静态面孔作为刺激。神经影像学研究表明，与面部表情处理相关的大脑区域（杏仁核，脑岛）对动态情绪表达的反应比对静态情绪表达的反应更激烈。此外，作者报告了神经学上受影响的个体无法识别静态面部表情，但能够识别动态表情的案例。所以，在处理现实生活面部表情的研究中，使用动态表情更为合适。一项关于人员身份识别的研究结果则表明：与静态面孔相比较，时间同步的发音面孔对熟悉的声音的识别影响更大。因此，本研究利用生态相关的材料来评估情感表达的多感官本质，采用了最新标准化且进过验证的动态视觉和非语言声音的情绪表达片段。实验1中，参与者被要求按照呈现的听觉的、视觉的，或者使用一致或不一致的视听刺激来将恐惧和厌恶的表情分类。在实验2中，被试被要求支注意一种感官模态，来测试多感官情感交互的强制性。

# 2. 实验程序

1. 刺激

   将重点放在了“恐惧”和“厌恶”两种情绪表达上，从进化的角度上，这两种情绪的表达都有一个共同的目标，使用直接威胁来警告观察者。尽管这两种情绪都属于“负面情绪的范畴，但是厌恶和恐惧能够被清楚地分开来。视觉刺激来源于一组标准化的64动态面部表情刺激，这都是典型的面部表情。听觉刺激来源于”Montreal affectivevoices“，这是一套标准化的情感声音表达，目的都是研究听觉情感处理，避免语言内容的潜在混淆。双峰刺激则是通过同时呈现视觉和听觉片段来获得，听觉和视觉刺激的呈现可以是一致（音频和视频表达相同的情绪，如呈现恐惧的表情的同时呈现恐惧的声音刺激)，也可以是不一致（音频和视频表达不相同的情绪，如呈现恐惧的表情的同时呈现厌恶的声音）。

2. 操作步骤

   参与者坐在一个安静、黑暗的房间里。使用演示软件在戴尔XPS笔记本电脑上运行，使用WindowsXP操作系统显示刺激。使用Logview记录行为反应和反应时间，这是一款专门用于分析Presentation获得的行为数据的定制软件。视觉刺激(宽度=10°视角;高度=12.5°视角)呈现在屏幕中央恒定的灰色背景上。通过使用床头枕，观看距离保持在60厘米不变。听觉刺激通过耳机(Philips HJ030)在自我调节的舒适水平下双耳呈现。

3. 实验1

   参与者被要求区分只呈现在视觉、或只呈现在听觉，或者试听上的恐惧和厌恶的情绪表达刺激，试听刺激可以是一致的，也可以是不一致的。一共向参与者呈现了480种刺激，这480种刺激随机交错在5个独立的96个刺激块中。初步结果显示，在不一致的视听刺激中，视觉占有优势，所以降低了视觉刺激的可靠性，以减少不一致条件下的视觉刺激。每个刺激呈现以后会有一个2000毫秒的灰色背景，在下一个刺激之前出现一个500-1500毫秒的中心交叉。

4. 实验2

   参与者被要求只注意一种感官模态，来测试多感官情感交互的强制性。在视觉条件下，参与者只看到视觉和视听上显示的刺激;视听刺激要么一致，要么不一致。在听觉条件下，参与者只被呈现听觉和视听刺激;视听刺激要么一致，要么不一致。在这两种情况下，我们在第一种情况下提供了无噪声刺激，在第二种情况下提供有噪声刺激。在这四种情况下，共有360个刺激，被分为5个独立的72个刺激块中。

5. 数据分析

   IE得分是将每种情况下的反应时间分别除以正确的反应率得到的。

# 3.结果

1. 实验1

   正如预期的那样，我们获得了因子“噪音”的主效应(F=16, p≤.001)，在无噪声刺激下比在有噪声刺激下表现得更好。在本研究中，我们还获得了“刺激”因素的主要影响(F=8, p≤0.002)，表明与单独的视觉(p≤0.01)和听觉(p≤0.005)刺激相比，双峰刺激的IE分数更低。ANOVA还揭示了“噪音”和“刺激”因素之间的显著相互作用(F=22，p≤10E-5)。事后分析显示，在两种噪声条件下，双峰性优于听觉刺激，但双峰性优于视觉刺激仅在噪声刺激下存在(p≤10E-6)。最后，我们还获得了“情绪”因子和“刺激”因子之间的显著交互作用(F=5, p≤0.01)，表明单模听觉恐惧刺激比单模听觉厌恶刺激更不容易被识别。在无噪声的视觉刺激下，参与者的反应倾向于视觉模态，而在有噪声的视觉刺激下，参与者倾向于将刺激分类为听觉模态所表达的情感类别。
   
2. 实验2

   当参与者参加视觉模态时，表现优于听觉模态。我们还获得了“噪音”因素的显著主效应(F=46, p≤10E-5)，证明了在刺激中添加噪声的干扰作用。重要的是，我们获得了“刺激”因素的强大主效应(F=43, p≤10E-7)，表明与单峰刺激相比，双峰一致刺激的表现更好(IE分数更低)(p≤0.02)，而与单峰刺激(p≤10E-5)或双峰一致刺激(p≤10E-7)相比，双峰不一致刺激的表现更差。

# 4.讨论

在研究中，参与者被要求区分“恐惧”和“厌恶”的情绪表达，这些情绪表达要么是通过听觉、视觉或者简短的动态面部和非语言的声音片段进行视听展示。

1. 实验1

  当被试以两种方式处理情绪信息时，与单峰条件相比较，参与者咋双峰条件下有更好的表现。当不一致的双峰对包含无噪声的视觉刺激时，参与者的反应更倾向于视觉模态。这一结果表明，在情感表达的感知中存在某种视觉优势或“视觉捕捉”。这可能与这样一个事实有关，即我们通过视觉传递的情感片段的感知强度被认为比通过听觉方式传递的情感片段更强烈。当参与者被呈现由嘈杂的视觉刺激组成的视听刺激时，参与者更频繁地将以听觉方式表达的情感进行分类。情感感知中的视觉优势并不是以一种僵化的、根深蒂固的方式发生的，而是遵循灵活的情境依赖规则，允许信息与最大效果相结合。

2. 实验2

  在实验2中，明确要求参与者一次只将注意力集中在一种感觉模态上，而完全忽略无关的模态，以此来研究情绪表达加工中的多感觉相互作用是否起源于自动的、强制性的感知过程，而不是后感知判断。当非目标模态与参与模态在情感上一致时，表现会增加，而当并发模态与目标感
  官通道中显示的表达不一致时，表现会下降。这些效应证明了情绪表达知觉中多感官交互的自动性。当参与的情态不太可靠时，参与者在处理双峰情绪表达时自动将更多的权重归给不相关的感觉情态。

  

  研究观察到，与听觉模态相比，当参与者参加视觉模态时，他们的整体表现更好。这一结果支持了这样一种观点，即至少在本研究中“恐惧”或“厌恶”歧视的情况下，视觉模态传递了最显著的信息。这也可能与这样一个事实有关，即当受试者关注听觉模态时，在刺激的双峰不一致条件下获得的表现下降比关注视觉模态时更大。

  

  最近的神经影像学研究表明，本研究中观察到的情感表达的组合可能在特定的解剖收敛区实现，可能在视觉和听觉模式之间，如左半球的杏仁核和颞中回。

  