---
title: 情绪-表情链接：来自人类和自动表达识别的证据
author: 范穗穗
date: 2021-02-14
showDate: true
showTOC: true
---
文献:Tcherkassof, A., & Dupré, D. (2020).The emotion–facial expression link: evidence from human and automatic expression recognition. *Psychological Research*, 1-16. https://doi.org/10.1007/s00426-020-01448-4
[论文原文](../Source_Files/2021-02-14-FSS1.pdf)
# 1.背景介绍
主观感受（subjective feelings）与面部表情（facial expressions）之间的一致性问题仍然是一个有争论的话题，一方面，“基本情绪视图（Basic Emotion View）”认为，面部表情是个人内在情绪状态的真实体现，因此，情绪识别是独立于感知者（perceiver）的；另一方面，建构主义方法（constructivist approach）认为情绪是由社会建构的，面部表情的含义由感知者推断，因此，情绪识别取决于感知者。很少有人使用纯粹的描述性方法，例如肌电图（electromyography）或客观的面部编码系统来识别和测量当感觉到给定的情绪时面部的实际变化。相反，许多研究都将重点放在了情绪面部表情（EFE）的识别上，也就是在感知者对面部显示的解释上。对情绪自发表达的研究并没有为基本情绪观提供强有力的支持。现有的证据表明，在自然和半自然环境中，情绪与其预测的面部表情之间的联系较弱。
许多人强烈认同所谓的基本情绪与特定的面部表情有关，并且认为这是基本情绪观的有力证据。而且，这意味着人类感知者的EFE识别应该与自动分类器一样准确。使用替代性识别方法（情绪饱足程序、面孔匹配任务、分类任务）可以证明，面部肌肉运动并非以一对一的方式链接到特定的离散情绪体验。取而代之的是，情绪可能是感知者在心理上构建的，因此需要情绪的心理类别来准确地将背景信息之间的面部运动分类。
# 2.研究目的
（a）检验普通人自我报告的情绪体验和感知者对这些普通人的EFE判断之间的一致性；（b）检验普通人自我报告的情绪体验与自动分类器对这些普通人的EFE分析之间的一致性。
# 3.方法
## 3.1被试：
358名编码被试（182位女性，176位男性，Mage = 47.9，SDage = 9.2）。
## 3.2情绪激发任务（emotion elicitation task）：
两种不同类型的任务被用来激发情绪。某些任务是被动的，包括让被试观看被选中以激发情绪的视频（例如，电视广告）。其他任务是主动的（active），要求被试与电脑互动(例如，回答问题或测试一个fawed软件)。使用隐藏式相机记录被试的面部，产生了358幅768×576正面视频，这些记录构成了DynEmo数据库。
情绪激发任务之后，被试使用李克特量（0(“不”)到5(“强烈”)）表对他们的主观感受进行评分，包括六种基本情绪(愤怒,厌恶,恐惧,快乐,惊喜和悲伤)和六种非基本情绪(骄傲,好奇心,无聊,耻辱,耻辱,和失望)。
## 3.3人工面部表情识别：
1383名被试参与，设置了一个迭代（iterative）过程，以确保每个记录都被至少20位被试标注。其中238个视频达到了标注量，每个视频平均被标注29次（SD = 12）。
标注过程遵循两个步骤：首先被试在观看视频时通过空格键控制情绪序列的开始和结束来识别情绪；其次，用12种情绪之一对视频进行标注。过程中为每一位感知者生成一维时间序列，记录视频的哪一秒识别出哪种情绪。然后，将对应于同一视频的时间序列汇总起来，以计算等式中每个情绪标签的视频每一秒的人类感知器xvideoi.labelj.tk的比例：
![图1](../Supporting_Information/2021-02-14-FSS1-Fig1.png)
其中，i是232个视频中的一个，j是六种“基本”情绪标签之一，视频中的每一秒是k。
## 3.4自动面部表情识别：
使用Afdex（SDK v3.4.1）处理了232个标注过的视频，在本研究中，仅分析了六种基本情绪。
对于人工识别和自动识别，要确定可以使用六种基本情绪中的哪一种来识别每个视频，将每个标签的识别概率逐帧转换为奇数比率。每个奇数比例时间序列的最高总和定义所识别的标签（有关人工识别，请参见方程（2），有关自动识别，请参见方程（3））。
 ![图2](../Supporting_Information/2021-02-14-FSS1-Fig2.png)
 其中，i是232个视频之一，j是六种“基本”情绪标签之一，k代表n秒视频的每一秒或f帧视频的每一帧。
# 4.结果
## 4.1人类感知者的准确性：
自我报告的情绪与人类感知者识别之间的识别和不识别的总体相关性是显著的，但较低；结果表明，被试在情绪激发过程中所感受到的情绪与人类感知者所识别的情绪之间的一致性较低。
情绪标签的准确度指标表示正确/错误识别比率的差异，幸福和厌恶的得分最高，而愤怒、惊奇和悲伤的识别率最低。
## 4.2自动分类器的准确性：
与之前的分析相似，识别和不识别的整体相关性显示自我报告的情绪与自动分类器的识别之间的相关性很低；除了快乐外，自我报告的情绪与自动分类器识别的情绪之间的一致性较低。
## 4.3人与自动识别的比较：
人类感知者似乎比自动分类器更能准确地识别一个人的主观感受，实际上，人类感知者与自动分类器之间的总体一致性非常低。
# 5.结论
当面对情绪激发任务时，自动展现的表情既可以被人类识别，也可以被自动分类器识别。结果首先显示情绪感受和显示的面部表情之间的一致性较低；其次，人类和自动分类器基于面部表情识别这些表达者的内在情绪状态的准确率均较低；第三，人类感知者被证明比自动识别工具更能识别面部表情。越来越多的证据表明，面部表情实际上并不能表达内在情绪。
