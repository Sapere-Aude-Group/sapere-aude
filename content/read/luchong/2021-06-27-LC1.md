---
title: 颞叶和额顶叶在跨视觉和语言表征动作中的不同作用
author: 卢冲
date:   2021-06-27
showDate: true 
showTOC: true  
---
文献名称
Wurm, M. F. , &  Caramazza, A.  (2019). Distinct roles of temporal and frontoparietal cortex in representing actions across vision and language.*Nature Communications*
https://doi.org/10.1038/s41467-018-08084-y
[原文](../Source_Files/2021-06-27-LC1.pdf)

# 1.引言
神经科学的中心问题是具体的细节感知到一般概念在大脑中的处理位置，但其仍没答案。研究发现表明，颞叶皮质编码从感知动作中的各种细节中提取出来动作表征 ，顶叶皮质前部表征了概括跨知觉细节的动作。这两个区域也是在动作词的语义加工过程中被激活的。这些发现提出了一个令人困惑的问题：如果颞叶皮质后部和顶叶皮质前部都能够以类似的、高度概括性的方式表征动作，那么它们在识别和记忆中的不同作用是什么？这两个区域似乎不太可能拥有相同的功能，并以重复的方式存储相同的(可能是概念性的)信息。
知觉细节的表征与特定的通道或刺激类型有关，而概念表征通常可以通过不同类型的刺激（例如，通过观察或通过阅读文本）来获得。神经成像研究表明，通过观察和从书面句子中理解动作，激活了前额叶和顶叶皮质以及枕颞脑区重叠的大脑网络，特别是在颞中后回(PMTG)和颞叶外侧后部皮质(LPTC)周围。大脑区域可能存在空间重叠但功能独立的神经群体，每个群体都是通过一种刺激类型来激活。到目前为止，是否有任何已确定的大脑区代表了可以通过不同类型的刺激(如视频或句子)获得的动作的概念性层面，尚无定论。
应用了一种更严格的方法，交叉模态多体素模式分析(MVPA)，来识别特定于动作的动作表征，但同时概括了对视觉场景和句子的感知理解。通过训练分类器（（classifier））来区分视频中观察到的动作，并测试同一分类器来区分相应的动作句子的准确性，该方法对动作视频和句子在空间上对应的激活模式很敏感，指向两种刺激类型共同获得的动作表征。此外，我们使用了第二个保守的标准来测试不同刺激类型的激活模式是否与概念表征兼容：与不同动作相关的神经活动模式应该彼此或多或少相似，这取决于动作之间共同享有更少还是更多的概念特征。我们使用通道态表征相似性分析(crossmodal representational similarity analysis    RSA)来测试语义模型是否能够预测通跨道动作表征的相似性，从而允许我们通过一般刺激的动作表征指定捕获动作的某一层面。研究表明，LPTC编码的概念性动作信息可以独立于刺激类型获得，而额顶叶区则以特定于刺激类型的方式表征动作信息。
# 2.结果
## 2.1步骤
在两个功能磁共振成像(FMRI)节段session中，被试识别视频中呈现的动作和相应视觉呈现的句子(图1)。被试通过回答不完整或无意义的动作视频以及语法或语义错误的句子来执行Catch试验检测任务。session顺序在参与者之间是平衡的。
![图1](../Supporting_Information/2021-06-27-LC1-Fig1.png)
## 2.2跨通道动作分类
使用探照灯分析，我们进行了两种类型的MVPA来识别编码刺激的大脑区域--一般的和特定于刺激的动作表征。为了识别跨刺激类型的动作表征，我们训练了一个分类器来区分动作和视频刺激，并在句子上测试了分类器，反之亦然。这项分析发现左侧LPTC有一个单一的簇，峰值位于pMTG，向背侧延伸至颞后上沟(PSTS)，向腹侧延伸至颞下回(图2a，表1)。
相比之下，如果分类器在动作视频内或句子内进行训练和测试，则可以在枕颞叶、额叶和顶叶重叠的更广泛的网络中区分动作(图2b)，这与之前的研究结果一致。总体而言，分类器准确率视频高于句子。一些区域对观察的动作特别敏感(左右两侧枕颞叶皮质和前下顶叶皮质)，而其它区域对句子动作特别敏感(左后颞上回和额叶下回、颞叶前部)。大部分额顶叶皮质区分视频和句子中的动作，但这些区域缺乏跨通道解码，表明这些表征不能在不同刺激类型中generaliize。

为了更详细地研究跨通道和节段（session）内解码在额顶叶和颞叶的差异效应，我们基于动作的视频基线和动作的句子基线的单变量激活图的结合，从感兴趣区域(ROI regions of interest )提取分类准确度(图2C)。
此联合显示左侧额下回(IFG)、左侧运动皮质前部(PMC)、左侧顶内沟(IPS)和双侧枕颞叶皮质延伸至LPTC。在所有的ROI中，视频内和句子内解码的概率明显高于机会水平，而跨通道解码只在LPTC中显示出显著的效果(图2d)。
为了量化和比较数据中H1(解码准确率高于机会水平)和H0(解码准确率不高于机会水平)的证据，我们使用定向贝叶斯单样本t检验执行贝叶斯模型比较。所有额顶叶ROI都显示在跨通道解码中H0(贝叶斯因子在0.11和0.21之间)有适度的证据，表明这些区域没有显著的高于机会水平的解码能力不太可能是由于设计不足所致。对ROI和解码方案的双因素方差分析显示，ROI和解码方案存在显著的交互作用和主效应。双尾配对t检验表明，LPTC的跨通道解码准确率显著高于其他ROI。综上所述，这些结果进一步证实，动作观察和句子理解过程中通常被激活的区域可能基于不同的原则：LPTC包含关于动作场景和句子的信息，这些信息可以在刺激类型内和跨刺激类型之间解码，而额顶叶包含只能在刺激类型内解码而不能跨刺激类型解码的信息。
左LPTC刺激类型的泛化可以用言语或视觉意象来解释吗？我们的实验设计允许测试这些可能性：当我们在被试之间平衡视频和句子节段（session）的顺序时，我们预计从句子节段开始的被试组会有更强的言语表达，而从视频节段开始的被试组会有更强的视觉意象。对比两组解码图，左侧LPTC无显著差异。此外，我们还发现LPTC的解码准确率与功能磁共振成像后言语化和视觉表象的评分之间没有显著的相关性。总而言之，这些对照分析没有发现支持这样的假设，即视觉意象和言语化解释了观察到的跨通道解码效应。
由于这些动作针对不同类型的接受者(人、无生命物体和手臂/手)，因此分类可能仅由接受者的信息驱动，为了测试LPTC中识别的簇是否与与研究的动作接受者相似的不同对象类别的视觉加工相关的大脑区域重叠，我们将LPTC簇的范围与全身、手和工具的定位的峰值位置进行了比较。对应于这些对象类别的区域位于LPTC的腹侧和更后方，并且与LPTC基本没有重叠。我们还研究了重叠部分，其使用跨通道MVPA进行识别区分对象类别。这些效应与LPTC也没有明显重叠。综上所述，是由对象的特定信息而不是动作推动进行跨通道动作分类。
## 2.3跨通道多元回归RSA
在动作观察和句子阅读过程中，动作特异性表征的可及性表明LPTC在动作理解中起着核心作用。这些表征到底编码了什么？使用多元回归RSA，我们更详细地分析了LPTC中动作表示的结构。为此，我们为每个被试提取了成对的跨模态分类准确率，以构建神经相异矩阵，该矩阵反映了动作相互区分的程度，从而反映了动作表征彼此之间的不同程度(图3A)。我们发现，LPTC中的神经动作差异可以通过人物和对象导向的模型来预测，该模型基于fMRI后的评级，即实验中显示的动作在多大程度上考虑了其他人的反应(个人导向)，以及这些动作在多大程度上涉及到与物理的非生命物体的互动(对象导向，图3B)。神经表征相似性的额外差异可以用更普遍的语义动作相似性模型来解释，群组动作以语义动作关系结合为基础。回归中包含的用于控制不感兴趣的因素(语义对象相似性、任务难度、动作的异常)的其他模型不能解释进一步的差异。
不感兴趣因素(语义对象相似度、任务难度、动作异常度)的回归控制包含的其它模型无法解释进一步的差异。
RSA效应在ROIsize以及在分析中(补充图4)所含的模型数量上都是稳健的，不受节段顺序、言语或视觉图像的影响(补充图5)。
此外，我们还发现，基于评分的人和物定向模型与神经动作差异的相关性显著好于基于实验中使用的主要刺激维度的简单类别模型(图3C）。这表明，LPTC中的神经表征组织确实反映了通过行为判断衡量的人和物指向性的刺激变化，而不是其他可能意外地与刺激维度一起变化的隐藏因素。最后，我们测试了基于个人评分的模型是否优于基于群体平均评分的模型。与个体模型相比，群体平均模型与神经异质性的相关性略高，但差异不显著。
## 2.4ROI路径RSA
跨模态动作信息可以从LPTC中相对较大的簇，其从pSTS至颞下回，解码。这一地区是否被划分为不同的子区域，专门从事某些方面的行动？基于先前的发现，我们假设，与人和对象导向相关的概念信息在LPTC中不是均匀分布的，而是遵循一个独特的功能地形图，它平行于更后面区域的已知梯度，分开有生命和无生命的对象知识以及生物和功能工具运动。为了研究表征内容如何从背侧颞叶皮质到腹侧颞叶皮质的变化，我们绘制了个人指向性和物体相关模型的表现，作为从跨模式解码簇的背侧到腹侧皮质向量位置的函数(图3D)。与我们的预测一致，我们发现个人定向模型在pSTS水平上解释了背侧LOTC的大部分变异，而物体定向模型在pMTG水平上腹侧达到顶峰(双因素方差分析 交互作用 位置×模型：F(15,300)=4.23，p<0.001)。
# 3.讨论
概念表征一般应该独立于刺激的通道或类型，例如，一个人是观察一个动作还是阅读相应的语言描述。这里我们表明，仅在动作观察和句子理解过程中激活的重叠并不能作为不依赖于刺激的概念表征获得的证据。使用交叉模式的MVPA，我们发现只有左侧的LPTC揭示了神经活动模式，这些模式既针对不同的动作，同时也概括了动作场景和句子。如何解释LPTC中动作场景和句子之间的特定动作对应关系？

一种可能性是，跨模式解码是由于视觉意象(在阅读句子时)或言语(在观看动作场面时)。如果是这样的话，LPTC中的解码信息是口头形式的，由句子和动作场景的言辞触发，或者是视觉形式，由观察到的动作场景和句子的意象触发。然而，控制分析并不支持这种可能性：跨模态解码的强度不受节段顺序、被试的言语倾向或想象动作的影响，也不受言语和句子之间或想象和观察到的动作之间的对应强度的影响。然而，言语化或意象化可能是如此隐含和自动，以至于它们没有被参与者的主观评分所捕捉，节段顺序并没有实质上影响言辞或想象动作的倾向，或者回顾以前经历过的动作场景和句子对言语化或表象化没有可衡量的影响。然而，这些假设不能解释为什么言语或意象的影响导致动作视频和句子之间的匹配，只出现在左LPTC中，而不是在视频内或句子内解码中发现的其他大脑区域。第二种可能性是，携带这两种刺激类型的特定动作信息的神经群体在功能上是独立的，但在单个体素内彼此相邻。虽然这种情况是可能的，但它会提出一个问题，即动作场景和句子的表征之间的这种逐体素对应的目的，以及为什么左LPTC是唯一具有该表示简档的区域。总而言之，这些反对意见都不能否认，左LPTC揭示了一种与额顶叶区完全不同的代表性特征。考虑到我们拥有的关于这个区域的神经成像、神经心理学和虚拟损伤证据(参见参考文献的综述)，最可信的解释似乎是，左LPTC编码了一个概念性的表征水平，可以通过不同的模态和刺激类型(如动作场景和句子)来获取。这一解释得到了交叉模态RSA的进一步支持，它揭示了LPTC中刺激-一般信息的组织可以通过描述动作的基本概念性方面的模型来预测，即施事-受事关系(人和物体导向)以及动作概念之间更复杂的语义关系，如动作是彼此的子部分还是相互对立的部分。请注意，这里得出的结论涉及LPTC中表示的信息的细节，并未提及关于精确表示形式的持续争论。
额顶叶区区分动作场面和句子，但解码的表征不能概括这两种刺激类型。因此，与额顶叶表征相比，LPTC中的表征似乎更笼统和抽象，额顶叶表征似乎捕捉到了不同刺激类型的更具体的细节和属性。值得注意的是，与句子相比，观察到的动作更具体、更详细。动作场面相对于句子的更强解码似乎反映了这种细节丰富性的差异。解码的额顶叶表示可能捕捉到关于如何具体执行动作的信息。这种与运动相关的表征可能由反映动作特定方面的动作场景触发，例如动作的运动学或在物体上使用的特定支配，而由句子触发的与运动相关的表示将不那么具体、更可变和不那么健壮。根据这一观点，在LPTC的概念激活之后，额顶叶运动相关表征被激活，这与经颅磁刺激引起的pMTG的扰动不仅阻碍动作动词的语义加工，而且与非运动动词相比，破坏了运动兴奋性的增加这一发现是一致的。同样，出生时没有手臂的发育不良者识别手部动作，他们没有相应的运动表征，速度和准确度与一般发育的参与者一样快和准确，这表明运动相关表征在获取动作概念时不是必需的。值得注意的是，在手部动作观察期间，发育不良和典型发育的个体之间额顶皮质的神经活动和表征内容没有差别。因此，另一种可能性是额顶叶区参与处理与刺激相关的非运动信息，例如，用于预测动作场面和句子如何展开。为了支持这一观点，运动前区和顶区被证明参与了对不同类型和模式的动态刺激的预测，即使刺激缺乏任何与运动相关的语用属性。
虽然这里报道的跨模态解码分析集中于识别刺激-一般动作表征的神经底物，而交叉模态RSA使我们能够更详细地研究这些表征的结构。我们发现，与实验中测试的动作相关的神经模式的相似性可以通过描述动作是针对其他人还是针对无生命物体的模型以及更一般的语义动作相似性模型来预测。由于仅以人和对象为导向并不能完全捕获动作的含义，因此LPTC似乎编码了有关动作语义方面的附加信息也就不足为奇了。这些额外的方面到底是什么还有待确定。我们的研究旨在调查捕捉到对其他人和无生命物体的动作指向性的表征。未来的研究应该测试其他相关维度(例如，指向演出者自己身体的方向、空间位置的改变)，并测试其他组织原则，这些原则只被语义动作相似性模型部分捕捉到，例如，因果顺序(决定开放和封闭之间的差异)或主题关系(捕捉动作是否像瞄准和射击一样是共同总体活动的一部分)。
值得注意的是，对人和物体指向敏感的表征遵循不同的功能结构：LPTC背侧部分的神经元群体对检测一个动作是否是人指向的更敏感，而腹侧部分的神经元群体对检测一个动作是否是物体指向的更敏感。这一结果重复了先前对观察到的动作的背腹梯度的观察，并表明刺激-一般动作表征也存在类似的(但左侧化的)梯度。以人和物体为导向的地形区别类似于通常在相邻的后部/腹侧区域中发现的相关梯度：在与本研究中发现的簇的后部重叠的枕颞外侧皮质中，背侧亚区优先由有生命的物体(例如，动物和身体部位)激活，而腹侧亚区优先由无生命的对象(例如，可操纵的人工制品和工具)激活。同样，背侧亚区优先被身体运动激活，而腹侧亚区优先被特定动作的工具运动激活。在这里，我们为更复杂的动作组件演示了这种区别的延续，这些动作组件不能用视觉刺激属性来解释。物体、物体运动和通道-一般动作表征的地形图排列指向了颞枕叶皮质中动作和物体知识的总体组织原则：与人相关的知识被表征在枕颞叶背侧皮质，并与背侧LPTC中的生物运动和个人定向动作特别相关(并形成其知觉基础)。此外，关于无生命可操纵物体的知识在腹侧枕颞叶皮质中被表征，并与腹侧LPTC中与动作相关的物体运动模式和物体定向动作特别相关。枕侧皮质和颞叶皮质的对象和动作知识在功能上的平行组织分别表明，沿着前-后轴的特定领域的对象-动作连接的重要作用，这与连接性在形成不同知识类别的功能组织中起着基础性作用的观点一致。根据这一观点，LPTC编码整合了来自相邻后部区域的更基本的前兆(例如关于人和物体的信息)的表示。这一观点得到以下发现的支持：LPTC是为主题相关的对象对激活的，即，与分类学上相关的对象对(例如，锯木、松鼠坚果)相比，通过动作或事件链接的对象对，即属于同一对象类别(例如，锯锤、松鼠狗)，后者激活枕叶皮质中更多的后部区域(但请注意，分类学上的对象关系也与前颞叶相关；参见参考文献)
综上所述，我们的结果表明，激活重叠并不一定意味着共同表征或功能的招募，交叉解码是检测重叠活动模式中是否存在表征对应的有力工具。具体地说，我们揭示了额顶叶和颞叶皮质在以刺激依赖和非独立方式表征动作信息方面的根本差异。这一结果可能对额顶叶和颞叶区域的表征轮廓及其在语义记忆中的作用提供新的线索。这些区域的不同概括性水平表明，从枕颞区的特定知觉刺激特征到左侧LPTC的更一般的概念性方面，再到额顶皮质的刺激特异性表征，动作表征的层次结构是不同的。我们认为，概念动作知识的地形组织(至少部分)取决于更基本的前体的表示，如有生命和无生命的实体。
# 3.方法
受试者。22名以右利手为母语的意大利语者(9名女性，平均年龄23.8岁，年龄范围20-36岁)参加了这项实验。所有被试的视力正常或矫正到正常，没有神经或精神疾病的病史。一名受试者因在任务中的行为表现不佳而被排除在外(准确度低于群体平均水平2个标准差)。所有程序都由意大利特伦托大学的伦理委员会批准，用于涉及人类参与者的研究。
刺激物
视频刺激包括24个样本的8个手部动作(总共192个动作视频)。行为在两个维度上有所不同，人的指向性(这里的定义是行为考虑他人的行为和反应的程度)和物体的指向性(这里的定义是行为涉及到与物理的无生命物体的互动的程度)，导致了四个动作类别：拥有的改变(物体导向/人导向)：给予、索取；物体操纵(物体导向/非社交)：开放、关闭；沟通(非物体导向/人导向)：同意、不同意；身体/接触动作(非物体导向的/非人导向)轻抚，抓。通过对每个动作使用24个不同的样本，我们增加了刺激的感知方差，以确保分类是基于概念特征而不是感知特征来训练的。差异是通过使用两个不同的背景、三个视角、两个演员和六个出现或涉及行动的不同物体(厨房背景：糖杯、蜂蜜罐、咖啡罐；办公室背景：瓶子、笔盒、铝盒)而引起的。视频catch试验包括每8个动作中的6个偏离样本(例如，无意义的手势或物体操纵、不完整的动作；总共48个捕捉试验视频)。所有240个视频在动作时间上都是相同的，即视频开始时双手放在桌子上，然后是动作，最后双手移动到桌子上相同的位置。视频是灰色的，长度为2s(每秒30帧)，分辨率为400×225像素。
句子刺激物与视频刺激物在刺激方差方面进行匹配(8个动作的24个句子；总共192个句子视频)。所有句子都有主谓宾语结构。对于每个动作，我们首先定义了相应的动词短语：dà(他给予)，prende(他接受)，apre(他打开)，chiude(他关闭)，si strofina(他揉她/他的)，si gratta(他挠她/他的)，fa Segno di Approvazione a(s/他做一个同意的手势)，fa Segno di disproval vazione a(s/他做一个手势)，a/he‘s/he做一个手势。为了在每个动作中创建24个样本，我们将每个动词短语与六个主题(她、他、女孩、男孩、女人、男人)和四个宾语(尽可能与视频中使用的宾语匹配)交叉：lei、lui、la ragazza,il ragazzo ,la donna l uomo、(她、他、女孩、男孩、女人、男人)四个物体，这与视频中使用的物体尽可能地匹配。交换财产：La Scatola，il vaso，il Caffe，lo zucchero(盒子，罐子，咖啡，糖)；物体操作：la bottiglia，il Barattolo，la Cassetta，l‘astuccio(瓶子，罐子，棺材，铅笔盒)；交流：l’Amica，l‘Amico，il College，la collega(朋友，同事)；身体动作：il brcio，la mano，il gasuccio(朋友，同事)；交流：l’amica，l‘amico，il College，la collega(朋友，同事)；身体动作：il brcio，la mano，il gasuccio(手臂、手、肘部、前臂)。由于交叉模态分析侧重于句子和视频刺激之间的泛化，忽略了动作句之间的感知和句法差异，如句子长度和介词出现的次数。Catch Trial句子由八个动作中每一个动作的六个语法错误或语义奇怪的例句组成(例如，lei apre alla bottiglia(她打开瓶子)，lui dàl‘amica(他给朋友)；总共48个CatchTrial句子)。这些句子以三个连续的块(主语、动词短语、宾语)叠加在浅灰色背景(400×225像素)上呈现，每个块显示666ms(每句话2s)，使用不同的字体类型(Arial、Times New Roman、Comic Sans MS、MV Boli、MS UI哥特式、Calibri Light)和字体大小(17-22)来增加句子刺激的知觉差异(在实验运行中跨条件平衡)。在扫描仪中，刺激通过液晶投影仪(OC EMP 7900，Epson Nagano，日本)反投影到屏幕(60Hz帧速率，1024×768像素屏幕分辨率)上，并通过安装在头线圈上的镜子观看(视频呈现6.9°×3.9°视角)。刺激呈现、响应收集和与扫描仪的同步由ASF51和用于Windows52的Matlab Mental Toolbox-3控制。
任务
在功能磁共振成像之前，我们只指导和培训了第一个节段的被试(视频或句子)。在第一次训练的四次之后，第二次训练在扫描仪内进行指导和练习。参与者被要求专心观看视频(朗读句子)，并在观察到的动作无意义或执行不完整或不正确时(当句子无意义或语法错误时)用右手食指按下响应按钮框上的按钮。因此，该任务引导参与者理解这些动作，同时最大限度地减少其他认知过程的可能性，这些认知过程可能在不同的动作之间有所不同，但在不同的会话中可能是相似的。例如，要求对动作熟悉度等特定维度的动作进行判断的任务可能会导致与准备不同反应相关的不同神经活动，这可能是各种刺激类型都可以辨别的。参与者可以在视频/句子期间或在视频/句子之后的注视阶段做出反应。为了确保参与者正确地遵循说明，他们在各自节段之前完成了一次练习。在实验之前，参与者没有被告知这项研究的目的和设计。
功能磁共振成像检查
在功能磁共振成像节段之后，参与者判断了实验中动作的人和物的定向程度。对于每个动作，参与者回答了以下问题的评分：物体指导性：“这个动作涉及到多少与物理的、无生命的物体的互动？”以人为本：“行动在多大程度上考虑了另一个人的行动和反应？”此外，他们还被要求评估他们在视频环节中用言语表达动作的程度(言语表达：“在观看动作视频的过程中，你有没有用言语表达这些动作，也就是说，你脑海中有没有像是在自言自语一样的语言描述(词语、句子)？”)，他们在视觉上想象了多少句子会话中的动作(意象：“在阅读句子时，你是否在视觉上想象出具体的动作场面？”)，以及他们的言语描述与句子有多相似(言语-句子对应)。(形象化：“在阅读句子的过程中，你是否在视觉上想象出具体的动作场景？”)，以及他们的言语描述与句子有多相似(言语-句子对应)。对于所有的评级，都使用了6分的利克特量表(从1分=完全不 到6分=非常多)。
表征差异性模型
为了研究编码跨模态动作信息的体素模式的表征组织，我们测试了以下表征差异模型：为了生成个人和物体指向性的模型，我们从个人和对象导向的评级中计算了对每个行动的群体平均反应之间的成对欧几里得距离。为了进行比较，我们还测试了分类模型，这些模型将行为按照人和物体的指向性分开，而没有考虑到更微妙的特定于行为的变化。为了测试动作之间的语义关系(以下称为动作语义)的探索性模型，该模型不仅基于人或对象，而且反映动作概念之间的语义关系，我们基于WordNet2.1计算动作概念之间的层次距离。该模型捕获动作之间的语义关系的组合，例如动作是彼此的子部分(例如，喝酒需要吞咽)还是彼此对立(例如，打开和关闭)。我们使用WordNet是因为它应该反映单词之间的概念语义关系，而不是语法关系。因此，语义关系应该既适用于动作句子，也适用于视频。我们通过识别意大利语中与动作句子中使用的动词相匹配且最符合动作含义的认知同义词(同义词集)来选择动作动词(“open.v.01”、“close.v.01”、“give.v.03”、“tak.v.08”、“stroke.v.01”、“”scratch.v.03“”、“accese.v.01”、“”discore.v.01“”)。我们使用最短路径长度度量来计算八个动作之间的成对语义距离，该距离反映了动作概念之间的分类距离。
以类似的方式，我们生成了四个动作类别(物体语义)中动作的目标对象(无生命对象、身体部位、人物)之间的语义关系模型。对于动作动词，我们选择了与句子中的宾语名词相匹配的意大利语同义词。因为每个动作类别有四个对象，所以每个类别内的距离是平均的。
为了建立任务难度(RT和错误)的模型，一组独立的参与者(N=12)进行了一项行为双选择强迫选择实验，该实验的设计和指导与功能磁共振实验相同，不同之处在于参与者用右手食指反应纠正动作视频/句子(动作试验)，用右中指反应错误动作视频/句子(捕捉试验)。对所有参与者的行动试验的正确反应的错误和反应时间进行平均。通过计算句子会话的8个准确度和视频会话的8个准确度之间的成对欧几里得距离来构建误差模型。因此，该模型反映了这八项行动在两次会议上犯下的错误有多么相似。RT模型是以类似的方式构建的，只是在计算距离之前对每个会话的RT进行z评分，以消除视频和句子RT之间与会话相关的差异。
为了生成一个模型来反映由于动作之间的异常而导致的潜在显著性差异，我们要求上一段描述的行为实验的参与者分别判断视频和句子中的动作有多不寻常(使用6分Likert量表，从1=完全不是到6=非常不寻常)。通过计算句子会话的8个平均回答和视频会话的8个平均回答之间的成对欧几里得距离，构建了异常模型。
数据采集
使用4T Bruker MedSpec Biospin MR扫描仪和8通道鸟笼头部线圈收集功能和结构数据。功能图像采用T2*加权梯度回波平面成像(EPI)序列进行脂肪抑制。采集参数为重复时间(TR)2.2s，回波时间33ms，翻转角(FA)75°，视野(FOV)192 mm，矩阵大小64×64，体素分辨率3×3×3 mm。我们使用了31个切片，按递增交错顺序获得，厚度为3mm，间隙为15%(0.45mm)。将切片倾斜，使其与颞上沟平行。在每一次功能运行中，采集了176张图像。在每次运行之前，我们执行额外的扫描来测量采集序列的点扩展函数(PSF)，以校正高场成像所预期的失真。用MPRAGE序列采集结构T1加权图像。
预处理
使用BrainVoyager QX 2.8(BrainInnovation)结合BVQXTools和NeuroElf工具箱以及用Matlab(MathWorks)编写的定制软件对数据进行分析。根据每次EPI扫描前获取的PSF数据，校正回波平面图像中的几何和强度失真。删除了前四个卷以避免T1饱和。第一次运行的第一个体积与高分辨率解剖学(六个参数)对齐。对数据进行三维(3D)运动校正(三线性插值，以每个参与者第一次运行的第一体积为参考)，然后进行切片时间校正和高通滤波(截止频率为每次运行三个周期)。空间平滑采用8mm全半高斯核(FWHM)进行单变量分析，3mm半高宽(FWHM)进行MVPA分析。利用三线性插值法将解剖和功能数据转换到Talairach空间。
动作分类
对于每个参与者、会话和运行，使用包含16个动作预测器(每个动作2个预测器，每个预测器基于从每个运行的前半部分(块1-3)或后半部分(块4-6)中选择的6个试验)、捕捉试验以及由3D运动校正(x、y、z平移和旋转)产生的6个参数的设计矩阵来计算一般线性模型。每个预测器与双伽马血流动力学脉冲响应函数卷积。每个试验都被模拟为从视频/句子开始到结束(2s)的一个时期。所得到的参考时间进程被用来拟合每个体素的信号时间进程。总体而言，这一过程导致每个动作条件和会话有8个Beta图。
使用半径为12 mm的探照灯球体和由CoSMoMVPA工具箱59和LIBSVM实现的线性支持向量机(SVM)分类器，在体积空间中分别对每个参与者进行Searchlight分类。我们通过从单个体素的每个贝塔中减去球体的平均贝塔来降低各个体素的探照灯球体中每个多体素贝塔模式的数据。降级是为了最大限度地减少分类器基于ROI中的全局单变量差异来区分动作的可能性，这些全局单变量差异可能是由于动作之间的非概念性差异(例如，一些动作场景可能包含更多与更少的动作信息、句子长度上的差异)而引起的每种刺激类型内的不同处理需求。在所有的分类分析中，每个动作都以成对的方式与其余七个动作中的每个动作区分开来(“一对一”多类解码)。对于探照灯分析，对八个动作的精确度进行平均(准确率概率=12.5%)，并将其分配给每个探照灯球体的中心体素。在跨模态动作分类中，我们使用视频会话的数据训练分类器来区分动作，并测试分类器对使用句子会话的数据区分动作的准确性。反之亦然(在句子数据上的训练，在视频数据上的测试)，结果的准确率在分类方向上被平均。我们还检验了概括顺序是否重要，即从动作视频(训练)到句子(测试)的概括是否导致了与从动作句子(训练)到视频(测试)的概括不同的聚类。然而，这两种概化方案产生了相似的地图，并且使用配对t-检验对比概化方案没有发现显著的聚类。在视频内动作分类中，我们使用Leaveone-Beta-Out交叉验证来解码视频会话的八个动作：我们训练分类器使用每个动作八个Beta模式中的七个来区分动作。然后，我们测试了该分类器在使用保持的数据区分动作时的准确性。该程序使用训练和测试模式的所有可能组合，在八次迭代中执行。所得到的分类精度在八次迭代中被平均。句内动作分类也采用了同样的程序。个体精确度地图被输入单样本t检验，以识别分类明显高于概率的体素。使用无阈值聚类增强(TFCE；在CoSMoMVPA工具箱中实现)对统计地图进行阈值处理。我们使用了10000次蒙特卡罗模拟和单尾修正的群集阈值p=0.05z=1.65。地图被投影到基于皮层的对齐的组表面上以进行可视化。没有观察到显著的低于机率的解码精度(使用双尾和单尾测试)。
ROI分析
为了具体研究在动作观察和句子理解过程中经常被激活的额顶和后颞区的跨模态解码和会话内解码的差异效应，我们进行了基于FDR校正的RFX对比动作视频和基线以及动作句子和基线的ROI分析。ROI建立在每个区域内连接峰周围半径为12mm的球体上(Talairach坐标x/y/z；IFG：−42/8/22，PMC：−39/−7/37，IPS：−24/−58/40，LPTC：−45/−43/10；除腹侧枕颞皮质外，右侧大脑半球均未观察到连接效应)。从每个ROI、分类方案(交叉模式、视频内、句子内)和参与者中，从探照灯地图中提取解码精度，并在体素之间求平均。平均解码精度进入方差分析、单尾样本t检验和贝叶斯比较。使用R(版本3.4.2)和Bayesfactor包(版本0.9.12)计算贝叶斯因子。使用单侧贝叶斯单样本t检验，我们计算了方向性贝叶斯因子，以比较标准化效应偶然性(12.5%)和偶然性以上的假设，效应大小的默认柯西先验宽度r=0.707。对解码映射的每个体素使用相同的过程来计算贝叶斯因子映射。
跨模态表征相似性分析
为了进一步研究编码交叉模态动作信息的体素中的代表性组织，我们使用交叉模态分类精度进行了基于ROI的多元回归RSA。ROI是基于在分类分析中识别的TFCE校正的群集来定义的。从每个感兴趣区域体素中提取跨模态动作解码的成对分类，得到体素8×8分类矩阵。值得注意的是，基于成对分类矩阵的对角数据的动作区别体素的选择不偏向RSA中调查的某些代表性组织，RSA基于成对分类矩阵的非对角数据(见下文)。分类矩阵在体素上平均，在主对角线上对称，并通过减去100-准确率(%)转换成代表性相异矩阵(RDM)，得到每个ROI和参与者一个RDM。对单个神经元和模型RDM的非对角线(即下三角部分)进行矢量化、z计分，并分别作为自变量和因变量进入多元回归。我们使用Matlab的Coldiag函数，通过计算条件指数(CI)、方差膨胀因子(VIF)和方差分解比例(VDP)来检验模型之间的假设共线性。这些测试的结果(最大。CI=3，最多。VIF=2.6，最大VDP=0.8)显示没有潜在估计问题的迹象。
相关系数经Fisher变换后进入单尾符号秩检验。根据回归中包含的模型数量对结果进行FDR校正。为了比较各个模型的性能，我们使用了基于相关性的τ算法，即我们使用Kendall的RDM工具箱实现的Kendall的RDM来计算神经RDM和模型RDM的非对角线之间的等级相关性。等级相关性的比较使用FDR校正的配对双尾符号秩检验来计算。
为了研究沿着背腹轴的模型的性能，我们使用了感兴趣区域路径分析：背侧和腹侧锚点分别基于交叉通道动作分类(Talairachx/y/z；背侧：−43/−58/20；腹侧：−43/−50/−10)中识别的簇的最背侧和腹侧体素。在平整的曲面上，锚点用直线向量连接。沿着该矢量，定义了一系列部分重叠的感兴趣区(半径12mm，中心间隔3mm)。如上所述，从每个ROI中提取、平均神经RDM，并将其输入到基于相关性的RSA中。得到的相关系数在参与者之间取平均值，并作为背腹轴上位置的函数绘制出来






