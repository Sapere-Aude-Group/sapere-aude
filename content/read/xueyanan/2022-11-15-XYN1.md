---
title: 汉语语义异常对竞争性视听刺激处理具有听觉优势
author: 薛雅楠
date: 2022-11-15
showDate: true
showTOC: true
---
文献：Pei, C., Huang, X., Li, Y., Chen, B., Lu, B., Peng, Y., ... & Xu, P. (2022). Auditory Dominance in Processing Chinese Semantic Abnormalities in Response to Competing Audio-visual Stimuli. _Neuroscience_, _502_, 1-9.
https://doi.org/10.1016/j.neuroscience.2022.08.017
## [论文原文](../Source_Files/2022-11-15-XYNQ.Pdf)
# 1. 研究背景及本研究
视觉系统的空间分辨率优于听觉系统，而听觉系统的时间分辨率优于视觉系统，语言理解通常需要多通道感觉输入，即口头语音和视觉文字来获取信息。当文字和语音表示相同的感知时，信息处理可能会更容易(Raij et al., 2000)。许多研究探索了视听竞争的潜在机制(Hirst et al., 2020)，有研究标明听觉机制占优势(Shams et al., 2000)，也有研究表明视觉机制占优势(Mishra et al., 2007)。N400效应对语义困难敏感。然而，信息冲突，即不一致的音位和字形输入，往往导致跨形态竞争(Robinson and Sloutsky, 2010)。那么，当听觉语音和视觉字符刺激发生冲突时，尚不清楚印欧语系的汉语是哪种方式占主导地位。
# 2. 本研究及实验流程
## 2.1 被试
招募了20名右利手的汉语母语者大学生被试
## 2.2 材料
构建了50个四音节的句子，其中前2个音节组成名词短语，后两个音节组成动词短语，每个音节的呈现时间为250ms，音节与音节之间无间隔，防止其他韵律线索对语言结构的构建产生影响。实验中，句子以完整和无序的视听方式呈现给被试。共包括3种实验条件：视听一致条件（udio-visual congruent condition ，AVC），听觉不一致状态(AI)和视觉不一致条件(VI)。其中在AI条件下视觉和听觉刺激同时呈现，视觉刺激中呈现的音节构成有意义的句子，但是听觉刺激中呈现的音节与其相邻音节不能构成有意义的内容。而VI条件下则相反，即听觉刺激中呈现的音节构成有意义的句子，而视觉刺激中呈现的音节不能构成有意义的内容。AVC条件下则视觉和听觉刺激一致，都构成前两个音节为名词短语后两个音节为动词短语的句子。
## 2.3 流程
研究包括闭眼休息状态下时长5分钟的脑电记录，和一个时长15分钟的视听任务。实验前2分钟要求被试深呼吸适应实验环境，然后记录5min静息状态脑电活动。实验共包括400个trial(AVC: 240, VI: 80,AI: 80)分成3个block，每个trial持续3s，以600ms的视觉聚焦+开始，然后呈现一个1s的句子，然后要求被试判断若为错误的听觉信息(按“1”键)，视听一致的信息(按“2”键)，或错误的视觉信息(按“3”键)，若被试超过1.2s按键或者按了其他键则被认为是无效按键。下一个trial之前有200ms的间隔，实验开始之前让被试尝试以确保了解实验规则。
![图1](../Supporting_Information/2022-11-15-XYN1-Fig-1.png)
## 2.4 数据处理
数据处理流程如下图所示，重参考为0，滤波0.1-10Hz，数据分段 [-200, 1000] ms其中0ms代表刺激开始时间。
![图2](../Supporting_Information/2022-11-15-XYN1-Fig-2.png)
# 3. 结果
## 3.1 行为结果
如下图所示，3种条件下的ACC具有显著不同，VI和AI的ACC也具有显著性；AVC条件下的RT与VI和AI条件下的也显著不同。
![图3](../Supporting_Information/2022-11-15-XYN1-Fig-3.png)
## 3.2 ERP分析
下图展示的是8个电极三种条件下的ERP对比，不同实验条件下N400振幅有显著差异。Bonferroni校正的两两比较显示，与AVC组或VI组相比，AI组的N400成分增强。
![图4](../Supporting_Information/2022-11-15-XYN1-Fig-4.png)
## 3.3 大脑网络的模式
通过以下步骤统计分析了不同条件之间的大脑连接模式：（1）采用重复测量单因素方差分析(Repeated measures one-way ANOVA)检验三种条件下的全脑连接强度是否存在显著差异。（2）事后检验进一步揭示了三种比较条件下的显著联系，图5A描述了重复测量单向方差分析所揭示的所有参与者的三种条件之间具有显著差异的联系。事后测试结果表明，AVC条件比VI或AI条件有更强的连接模式，此外，AI条件比VI条件具有更强的网络连接，主要表现为远程功能连接模式的增强（图5D）。AVC组的神经网络连接明显强于AI组，且显著性差异主要表现在左额枕区（图5B）；同样，与VI组相比，AVC组具有更强的网络连接模式，位于枕部和额部的远程功能连接（图5C）。
![图5](../Supporting_Information/2022-11-15-XYN1-Fig-5.png)
# 4. 讨论
本研究的问题是当被试接收到冲突的音位和字符信息时，哪种语态占主导地位？

行为学研究表明，ACV条件比AI和VI条件下被试的反应更快更准确，这表明视觉文字和听觉语音之间存在竞争，并且因为发生了视听竞争，大脑识别无意义语音比识别无意义中文句子更准确。尽管在被试在AV和VI条件之间的反应时无显著性差异，但是结果能看出在AI条件下花费的时间相对较少。因此这些结果表明被试在AI条件下表现比VI条件相对更好。

脑电研究表明，N400成分在不一致条件（AI和VI）比一致条件下（AVC）振幅更大，并且N400成分在AI条件下比VI条件下的振幅更大。与语音(听觉方式)相比，阅读是一种几千年来才出现的认知技能，到目前为止，人们普遍认为阅读习得是在进化过程中发展起来的，受益于口语系统(Karipidis et al., 2018)。在之前的研究中，Hu和同事(Hu et al.， 2012)指导参与者识别四字成语中的最后一个字是否正确，一方面，他们发现声调违反比元音违反引发了更强的后期正性成分，这表明对两种类型的信息进行了不同的再分析。

三种条件下的网络模式分析表明，当视觉字符合听觉语音信息一致的时候会招募更多与语言处理相关的神经资源。尤其是与语音失配条件下相比，视听一致条件下的连接模式具有左侧前额叶和颞叶区域之间更强的远程连接，左颞区负责将感觉或语音表征映射到词汇概念表征，而左额叶区负责存储和整合语言信息(Hickok and Poeppel, 2007)。这与之前的研究一致。在视觉形态下，单词的发音首先被可见的符号激活，然后从单词的发音过渡到意义，因此，视觉语态的效率可能不如听觉语态，因为听觉语态可以直接将语言信息从发音加工到意义。

研究论证了语音和汉字之间存在视听竞争。与视觉失配条件相比，听觉失配条件下的ACC更高、N400同时更大、枕顶后区连接更多，提示听觉优势在视听竞争发生时表现出来。
# 5. 局限
听觉语音是以音节为单位呈现的，而视觉字符是以句子为单位呈现的，导致保留了更多的视觉信息，可能会造成更强的视觉信息优势，因此未来的方向是视觉和听觉信息等时同步呈现来研究此问题。
