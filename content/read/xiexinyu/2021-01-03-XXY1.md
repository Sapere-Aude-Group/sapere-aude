---
title: 多模态语言分析融合策略的实证比较
date: 2021-01-03
author: 谢心雨
---

# 一、文献名称

Gkoumas, D., Li, Q., Lioma, C., Yu, Y., & Song, D. (2021). What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis. *Information Fusion, 66, 184–197.* http://doi.org/10.1016/j.inffus.2020.09.005 

# 二、研究背景

​	多模态视频情感分析是一个快速发展的领域。它结合了语言(即语言)和非语言形式(即视觉、听觉)来预测话语的情感。最近的一个趋势是利用不同的注意力、记忆和循环成分来建立不同的模式融合模型。然而，没有对多模态语言分析的不同最先进(SOTA)融合方法进行全面的实证研究。这种广泛的实证评价有助于发现SOTA方法中哪些方面在解决多模态语言分析问题上是最有效的。本文在三个广泛使用的多模态情感和情感分析基准语料库上复制和评估了最新的SOTA融合方法来建模人类语言。

# 三、目的及方法

研究以下三个问题：

1、当前基于机器学习的多模态融合策略对情感分析和情感识别任务的有效性如何?

2、SOTA多模态融合策略的效率如何?在多模态情感和情绪分析任务的背景下，该策略的有效性如何影响效率?

3、在多模态语言模型和融合策略中，哪些成分/方面是最有效的?

目标是从视频中推断出说话人的情绪。

## a、被试

未选择被试，实验采用的是数据集

## b、材料

数据集采用：CMU-MOSI:是一个相对平衡(1176个正面话语和1023个负面话语)的人类多模态情感分析数据集，包含2199个简短的独白视频片段(每个片段持续一个句子的持续时间)。它在训练集、验证集和测试集中分别有1284、229和686个话语。

CMU-MOSEI:规模更大的情感和情感分析数据集，由来自1000多名Youtube在线演讲者的22777个电影评论视频剪辑组成。训练集、验证集和测试集分别由16265、1869和4643个话语组成。

IEMOCAP：它由151个关于二元互动的视频组成，在这些视频中，专业演员被要求表演引起特定情绪的脚本场景。它在训练、验证和测试集上分别有2717、798和938个话语。

## c、过程

SODA模型：

#### c.1 Recurrent cell-based networks

包括Early-Fusion LSTM、Late-Fusion (LF-LSTM)、RMFN。这一类包括模态融合方法，它主要利用循环细胞进行每个时间步。在这种情况下，单元一个接一个地堆叠，实现了一个有效堆叠的RNN

#### c.2 Tensor-based networks

包括TFN和LMF.这组网络主要是基于模的张量积来进行信息的entangle和disentangle。

#### c.3  Attention mechanism-based networks

主要包括：MARN、MulT、MMUU-BA、REVEN。这些方法主要利用不同的注意机制成分来融合模式。

#### c.4 Memory-based networks

包括MFN，MFN是一个内存融合网络，它建立了一个多模态门控内存组件。这个类别扩展了带有记忆成分的循环神经模型，以模型模式交互作用。

#### c.5 Translation-based networks

包括MCTN,是一种具有一个源模态和两个目标模态的分层神经机器翻译网络。这类翻译包括通过将源语言模式转换为目标语言模式来建模人类语言的神经机器翻译方法。

# 四、研究结果

1、

![]()

Fig-1。从图1可以看出，所有的方法都在MOSEI任务上有所改进。此外，MulT和Raven在MOSI和MOSEI任务中产生了类似的性能。也就是说，它们表现出相似的学习行为。然而，MMUU-BA在MOSEI任务中表现出了积极的趋势，比MulT和RAVEN方法表现出了更明显的提高。在不考虑效率的情况下，我们发现MulT、MMUU-BA和RAVEN是最适合的情感分析模型，而MMUU-BA和MulT是最适合的情感识别模型。RAVEN在情感分析任务中表现出色，但在情感识别任务中表现最差。

2、

![]()

Fig-2。图2显示了MOSI上每个情感类的误差百分比。基于注意机制的方法，如MMUUBA、MulT和RAVEN，在积极情绪类中达到了最低的错误百分比。然而，基于张量的模态融合方法，如TFN和LMF，在消极情感类的性能上更有效。值得注意的是，RAVEN为正类实现了最低的错误百分比，却为负类产生了最高的错误百分比

Fig-3。描述了MOSEI上每个情感类的错误百分比。与MOSI不同的是，所有的方法对积极情绪类的错误率都很低，而对消极情绪类的错误率却很低。

3、

![]()

Fig-4。显示IEMOCAP上每种情绪的错误百分比。结果表明，快乐情绪类的误差百分比很高，大于64%。然而，有些方法，如MMUU-BA和MulT，比其他方法，如RAVEN和MFN更有效。也就是说，在不同的模态融合方法中有相当大的误差百分比差异。

# 五、讨论及其他

​	在未来的多模态情感分析中，如何考虑正在进行的话语和已有的知识库，这些知识库可能包含情感或情感知识，是值得研究的问题。在跨多模态序列(而不是相应的时间戳)的跨模态交互方面也很少投入精力。

​	文章中没有提及被试，应该是直接从数据集中获取的数据，因此整个实验没有涉及被试的选择。另外，所有的SODA模型，我不清楚是否涉及神经方面，同时模型太多，不能每一个都能理解清楚，同时如何得出的实验结果也不太清楚。

